services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: app
      POSTGRES_PASSWORD: app
      POSTGRES_DB: decision_engine
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app -d decision_engine"]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

  backend:
    build: ./backend
    working_dir: /app
    env_file:
      - .env
    volumes:
      - ./backend:/app
    environment:
      ALEMBIC_CONFIG: /app/app/alembic.ini
      DATABASE_URL: ${DATABASE_URL}
      APP_ENV: ${APP_ENV:-dev}
      HUD_USER_TOKEN: ${HUD_USER_TOKEN}
      RENTCAST_API_KEY: ${RENTCAST_API_KEY}

      # Celery
      CELERY_BROKER_URL: ${CELERY_BROKER_URL:-redis://redis:6379/0}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND:-redis://redis:6379/1}
      CELERY_QUEUE: ${CELERY_QUEUE:-celery}

      # Agents
      AGENTS_MAX_RUNS_PER_PROPERTY_PER_HOUR: ${AGENTS_MAX_RUNS_PER_PROPERTY_PER_HOUR:-3}
      AGENTS_MAX_RETRIES: ${AGENTS_MAX_RETRIES:-3}
      AGENTS_RUN_TIMEOUT_SECONDS: ${AGENTS_RUN_TIMEOUT_SECONDS:-120}
    command: bash -lc "alembic -c /app/app/alembic.ini upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    ports:
      - "8000:8000"
    restart: unless-stopped

  # ✅ Celery worker as a persistent service (NOT docker-compose exec)
  agent-worker:
    build: ./backend
    working_dir: /app
    env_file:
      - .env
    volumes:
      - ./backend:/app
    environment:
      DATABASE_URL: ${DATABASE_URL}
      APP_ENV: ${APP_ENV:-dev}

      CELERY_BROKER_URL: ${CELERY_BROKER_URL:-redis://redis:6379/0}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND:-redis://redis:6379/1}
      CELERY_QUEUE: ${CELERY_QUEUE:-celery}

      AGENTS_MAX_RETRIES: ${AGENTS_MAX_RETRIES:-3}
      AGENTS_RUN_TIMEOUT_SECONDS: ${AGENTS_RUN_TIMEOUT_SECONDS:-120}
    # ✅ Explicitly bind to the celery_app object + consume the same queue you publish to
    command: bash -lc "celery -A app.workers.celery_app:celery_app worker -l INFO -Q ${CELERY_QUEUE:-celery}"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  celery-beat:
    build: ./backend
    working_dir: /app
    env_file:
      - .env
    volumes:
      - ./backend:/app
    environment:
      DATABASE_URL: ${DATABASE_URL}
      APP_ENV: ${APP_ENV:-dev}

      CELERY_BROKER_URL: ${CELERY_BROKER_URL:-redis://redis:6379/0}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND:-redis://redis:6379/1}
      CELERY_QUEUE: ${CELERY_QUEUE:-celery}

      AGENTS_RUN_TIMEOUT_SECONDS: ${AGENTS_RUN_TIMEOUT_SECONDS:-120}
    command: bash -lc "celery -A app.workers.celery_app:celery_app beat -l INFO"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      - backend
    ports:
      - "8080:80"
    environment:
      NODE_ENV: production
    restart: unless-stopped

volumes:
  pgdata:
